{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelo de Clasificacion de Imágenes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM29enBd4WBz88o/fUAWTVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nyota-Lab/torch/blob/Modelo-de-reconocimiento-de-imagenes/Modelo_de_Clasificacion_de_Im%C3%A1genes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0ZIhT9hkpWK",
        "colab_type": "text"
      },
      "source": [
        "#Modelo de clasificacion de imagenes\n",
        "* Vamos a entrenar un modelo de clasificacion de imagenes usando el dataset normalizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AXwBowIdfDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import utils\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "import urllib.request as request\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnqRr2HPgCUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = 'data/'\n",
        "full_data_set = datasets.CIFAR10(data_path, train=True,download=True, transform=transforms.Compose([\n",
        "                                                      transforms.ToTensor(),\n",
        "                                                      transforms.Normalize(\n",
        "                                                          mean=[0.4915, 0.4823, 0.4468],\n",
        "                                                          std=[0.2470, 0.2435, 0.2616]\n",
        "                                                      )]))\n",
        "full_validation_set = datasets.CIFAR10(data_path, train=False,download=True, transform=transforms.Compose([\n",
        "                                                      transforms.ToTensor(),\n",
        "                                                      transforms.Normalize(\n",
        "                                                          mean=[0.4915, 0.4823, 0.4468],\n",
        "                                                          std=[0.2470, 0.2435, 0.2616]\n",
        "                                                      )]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvVi5VfLjQrF",
        "colab_type": "text"
      },
      "source": [
        "* Vamos a generar un dataloader que nos va a permitir hacer batchs de imagenes de acuerdo a el tamaño que decidamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuAtc8JZgCSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = 4\n",
        "dataloader = torch.utils.data.DataLoader(full_data_set, batch_size=size, shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpJ76sSrlkCO",
        "colab_type": "text"
      },
      "source": [
        "* Una vez tenemos nuestra funcion dataloader vamos a aplicarla en nuestro dataset a través de un iterador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cldcq7CjgCQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_iterator = iter(dataloader)\n",
        "imgs, labels = data_iterator.next()\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "plt.imshow(utils.make_grid(imgs).permute(1,2,0))\n",
        "for i in range(size):\n",
        "  print(classes[labels[i]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XliWTVGrPAp",
        "colab_type": "text"
      },
      "source": [
        "* Al ser una clasificacion binaria vamos a tomar dos clases del dataset y solo nos vamos a quedar con los resultados que ingresen dentro de una de las clases reclasificando las etiquetas e instanciando dos nuevos sets de datos y entrenamiento que solo van a tener las imagenes con las clases seleccionanas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRYisULNgCOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_name = ['automobile', 'cat']\n",
        "label_map = {1:0, 3:1}\n",
        "\n",
        "data_set = [(img, label_map[label]) for img, label in full_data_set if label in [1,3]]\n",
        "validation_set = [(img, label_map[label])for img, label in full_validation_set if label in [1,3]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGMgJik4gCMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img, label = data_set[20]\n",
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJPbvRY7rqIJ",
        "colab_type": "text"
      },
      "source": [
        "* Una vez tenemos nuestros datasets vamos a entrenar nuestro modelo.\n",
        "  * Usamos un modelo lineal con valores de entrada de acuerdo al tamaño de nuestras imagenes y su dimension y nuestro valor de salida van a ser 512 'neuronas'\n",
        "  * Nuestra capa oculta va a utilizar como funcion de activacion Tanh\n",
        "  * De nuevo llamamos al modelo lineal pero esta vez nuestro valor de entrada van a ser las 512 'neuronas' y nuestro valor de salida va a ser 2 ya que nuestro modelo es binario\n",
        "  * Agregamos la funcion Softmax debido a que queremos que nuestro resultado sea una probabilidad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIowSeMJgCIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "          nn.Linear(3*32*32,512),\n",
        "          nn.Tanh(),\n",
        "          nn.Linear(512,2),\n",
        "          nn.Softmax(dim=1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEiSyXEJgCB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img, label = data_set[30]\n",
        "plt.imshow(img.permute(1,2,0))\n",
        "class_name[label]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMbz-aRrgB9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = model(img.view(-1).unsqueeze(0))\n",
        "out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNg0Nx-wgB6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, index = torch.max(out, dim=1)\n",
        "print( class_name[label], '->', 'model:', class_name[index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0448aADSgB3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4u6tIexgB0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6mZESKIgByf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp6OzhOigBtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nESGgC5gBrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyjQkd5sgBpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Z2iYXqgBmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPI_0j-5gBhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JbFGG6TgBdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQsVSR7LgBbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwb8obWRgBZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRkPNUdggBWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfGlyr-kgBUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iU3MlIZgBRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftMwNml-gBN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aip-V0bggBKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Dclq0XgBGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}